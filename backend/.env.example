# HR Assistant RAG - Environment Configuration
# Copy this file to .env and update with your settings

# Flask Environment
FLASK_ENV=development  # development, testing, production
FLASK_DEBUG=true
PORT=51425

# Security (CHANGE THESE IN PRODUCTION!)
SECRET_KEY=your-secret-key-change-in-production
JWT_SECRET_KEY=your-jwt-secret-change-in-production
JWT_ACCESS_TOKEN_HOURS=24
JWT_REFRESH_TOKEN_DAYS=30

# Admin User (Created on first run)
ADMIN_PASSWORD=admin123  # CHANGE THIS IN PRODUCTION!

# Database
DATABASE_URL=sqlite:///data/hr_assistant.db
# For PostgreSQL (production):
# DATABASE_URL=postgresql://user:password@localhost:5432/hr_assistant

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_DEFAULT=100/hour
RATE_LIMIT_QUERY=50/hour
RATE_LIMIT_UPLOAD=10/hour
# RATE_LIMIT_STORAGE_URL=redis://localhost:6379  # For distributed rate limiting

# File Upload
MAX_UPLOAD_SIZE_MB=50
UPLOAD_FOLDER=uploads

# Vector Store / RAG
EMBEDDING_MODEL=all-MiniLM-L6-v2
FAISS_INDEX_PATH=data/faiss_index
CHUNK_SIZE=500
CHUNK_OVERLAP=50
RETRIEVAL_K=3
CONFIDENCE_THRESHOLD=0.3
MIN_CONFIDENCE=0.5

# === LLM Configuration (GitHub Models) ===

# Enable/disable LLM-powered responses
LLM_ENABLED=true

# GitHub Personal Access Token (no permissions needed)
# Get from: https://github.com/settings/tokens
GITHUB_TOKEN=ghp_your_token_here

# Model Configuration
GITHUB_MODELS_ENDPOINT=https://models.inference.ai.azure.com
GITHUB_MODELS_MODEL=gpt-4o-mini
GITHUB_MODELS_MAX_TOKENS=1500  # Increased for detailed responses (max 4000 for gpt-4o-mini)
GITHUB_MODELS_TEMPERATURE=0.1

# Caching (IMPORTANT for staying within 50 req/day limit)
LLM_CACHE_ENABLED=true
LLM_CACHE_TTL=86400              # 24 hours (since we have only 50/day)
LLM_CACHE_SIMILARITY=0.92        # Lower threshold for more cache hits

# Features
LLM_ENABLE_CITATIONS=true        # Include [Source N] in responses
LLM_FALLBACK_TO_TEMPLATE=true   # Use template if rate limited

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_DIR=logs

# CORS (comma-separated origins)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# API Keys (comma-separated, for backward compatibility)
API_KEYS=
